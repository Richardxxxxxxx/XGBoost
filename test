spark2-shell --master yarn --jars xgboost/jvm-packages/xgboost4j-spark/target/xgboost4j-spark-0.7-jar-with-dependencies.jar, xgboost/jvm-packages/xgboost4j/target/xgboost4j-0.7-jar-with-dependencies.jar --num-executors 1 --executor-memory 1G --executor-cores 1

import ml.dmlc.xgboost4j.scala.Booster
import ml.dmlc.xgboost4j.scala.spark.XGBoost
import org.apache.spark.sql.SparkSession
import org.apache.spark.SparkConf

val numRound = 2
val num_workers = 1
val inputTrainPath = "/tmp/agaricus.txt.test"
val inputValidPath = "/tmp/agaricus.txt.test"

val sparkConf = new SparkConf().setAppName("sparkWithDataFrame").set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
sparkConf.registerKryoClasses(Array(classOf[Booster]))
val sparkSession = SparkSession.builder().config(sparkConf).getOrCreate()
val trainDF = sparkSession.sqlContext.read.format("libsvm").load(inputTrainPath)
val testDF = sparkSession.sqlContext.read.format("libsvm").load(inputValidPath)

val params = List("eta" -> 0.1f, "max_depth" -> 2, "objective" -> "binary:logistic").toMap

val xgbModel = XGBoost.trainWithDataFrame(trainDF, params, numRound, num_workers, useExternalMemory = true)

xgbModel.transform(testDF).show()
